<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Devops on ChaosBlog</title>
    <link>https://blog.networkchallenge.de/tags/devops/</link>
    <description>Recent content in Devops on ChaosBlog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>de-de</language>
    <copyright>Copyright © ChaosBlog 2021</copyright>
    <lastBuildDate>Thu, 01 Aug 2019 16:00:00 +0800</lastBuildDate>
    
	<atom:link href="https://blog.networkchallenge.de/tags/devops/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Einstieg in Canary Deployments</title>
      <link>https://blog.networkchallenge.de/tech/k8s-einstieg-in-canary-deployments/</link>
      <pubDate>Thu, 01 Aug 2019 16:00:00 +0800</pubDate>
      
      <guid>https://blog.networkchallenge.de/tech/k8s-einstieg-in-canary-deployments/</guid>
      <description>Abstract Dieser Beitrag hat das Ziel, alle notwendigen Schritte aufzuzeigen, mit denen man eine DevOps-Pipeline in einem Kubernetes-Cluster aufbaut. Grundlegend basiert dies auf der sehr ausführlichen Anleitung in der GCP-Doku. Dabei wurde das Beispiel erweitert, um ein realistischeres Anwendungsszenario abzudecken: eine moderne Anwendung mit zugrundeliegender Microservices-Architektur die mit Canary-Deployments zu schnellen Production-Deployments führt und dabei die Gesamtqualität der Anwendung nur in einem kontrollierten Rahmen gefährdet. Dabei zeige ich die Herausforderungen auf, vor die uns ein klassisches Kubernetes-Cluster stellt.</description>
    </item>
    
    <item>
      <title>Jenkins-Pipeline einmal in der Zukunft ausführen</title>
      <link>https://blog.networkchallenge.de/tech/jenkins-pipeline-einmal-in-der-zukunft/</link>
      <pubDate>Thu, 16 May 2019 23:32:05 +1000</pubDate>
      
      <guid>https://blog.networkchallenge.de/tech/jenkins-pipeline-einmal-in-der-zukunft/</guid>
      <description>Manchmal macht es Sinn, dass ich im Blog einige Beiträge vorab schreibe und später veröffentlichen will. Da der Blog als statische Seiten mit Hugo generiert wird, muss die Erzeugung immer mit der Veröffentlichung erfolgen. Das lasse ich von einem bestehenden Jenkins bauen. Um einen Blogbeitrag nun für die Zukunft einzuplanen gibt es im Jenkins eigentlich nur eine Option: zeitgesteuerte Jobs mittels Cron.
Einen Job per Cron zeitgesteuert zu starten bedeutet aber auch ein Problem: der Job wird regelmäßig zum geplanten Zeitpunkt ausgeführt, immer wieder.</description>
    </item>
    
    <item>
      <title>Google Cloud Run ausprobiert</title>
      <link>https://blog.networkchallenge.de/tech/google-cloud-run-ausprobiert/</link>
      <pubDate>Fri, 19 Apr 2019 20:50:00 +1200</pubDate>
      
      <guid>https://blog.networkchallenge.de/tech/google-cloud-run-ausprobiert/</guid>
      <description>Abstract Ich befasse mich mit einem Java-Microservice, welches bei Google Cloud Run deployed wird und betrachte es als Alternative zu AWS Lambda. Dabei gehe ich auch auf das Thema Kaltstartzeit der Container ein und befasse mich in diesem Kontext auch mit den Vorteilen der GraalVM.
Google Cloud Next 2019 Dieses Jahr hat Google auf der eigenen Cloud-Messe Cloud Next wieder einige interessante Dinge vorgestellt, darunter Google Cloud Run. Cloud Run ermöglicht den Betrieb von Containern als HTTP-Endpunkte nur für die Zeit eines Requests.</description>
    </item>
    
    <item>
      <title>MongoDB-Cluster Verbindung durch Firewall</title>
      <link>https://blog.networkchallenge.de/tech/mongodb_verbindung_hinter_firewall/</link>
      <pubDate>Sun, 23 Sep 2018 15:52:41 +0200</pubDate>
      
      <guid>https://blog.networkchallenge.de/tech/mongodb_verbindung_hinter_firewall/</guid>
      <description>Auf Arbeit stand ich vor dem Problem, auf einem MongoDB Atlas-Cluster einen Dump einspielen zu müssen. Dafür ist aber die Benutzung der Kommandozeilenwerkzeuge mongodump und mongorestore unabdingbar. Die Herausforderung war aber eine, die mich regelmäßig quält: das Sicherheitsbedürfnis des Unternehmens steht an oberster Stelle und wir müssen somit immer über den Unternehmens-Proxy oder dedizierte Jumphosts gehen, die für bestimmte Verbindungen freigeschaltet sind.
Bei der Verbindung zu einem Replica Set steht man vor der Herausforderung, dass der Client eine Verbindung zu allen Nodes machen will und bekommt dabei die Serveradressen von der Gegenseite mitgeteilt.</description>
    </item>
    
    <item>
      <title>URLs einer Website testen</title>
      <link>https://blog.networkchallenge.de/tech/website_url_test/</link>
      <pubDate>Sun, 19 Aug 2018 13:27:00 +0200</pubDate>
      
      <guid>https://blog.networkchallenge.de/tech/website_url_test/</guid>
      <description>Aktuell hatte ich ein Problem mit einem Webprojekt. Einige Website-Resouren wurden sporadisch, ohne erkennbares Muster, nicht geladen. Um ein eventuelles Muster (oder eben nicht) zu erkennen, musste ein paar Hilfsmittel her.
Inventar erstellen Zuerst musste eine Url-Liste erstellt werden, mit allen zu prüfenden Resourcen. Dafür kommt wget zum Einsatz. Mit folgendem Befehlt lassen sich alle Urls von einer Hauptseite ermitteln:
wget --spider --force-html -r -l1 https://blog.networkchallenge.de 2&amp;gt;output.log  Das Output dieses Vorgangs verarbeiten wir nun weiter (es enthält viel mehr als die gesuchten URLs), um die finale Url-Liste zu erzeugen:</description>
    </item>
    
    <item>
      <title>Automatische Docker-Mounts in Windows</title>
      <link>https://blog.networkchallenge.de/tech/automatische-docker-mounts-win/</link>
      <pubDate>Wed, 22 Feb 2017 09:22:51 +0100</pubDate>
      
      <guid>https://blog.networkchallenge.de/tech/automatische-docker-mounts-win/</guid>
      <description>Standardmäßig wird bei der Installation der Docker Toolbox die freie Virtualisierungssoftware VirtualBox installiert. Um nun im Docker-Container auf Dateien des Windows-Hosts zuzugreifen, wird standardmäßig der Pfad /c/Users im Gastsystem gemountet. Dies ist aber nicht optimal, da man als Windows-Nutzer oft mit Leerzeichen in Pfaden geplagt ist und auch sonst eher z.B. mit einem anderen Arbeitsverzeichnis z.B. c:\dev arbeitet.
Damit dies nun bei jedem Start der Docker-Machine verfügbar ist, müssen ein paar manuelle Handgriffe getätigt werden.</description>
    </item>
    
  </channel>
</rss>